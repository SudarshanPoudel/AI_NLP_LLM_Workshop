{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167923f6",
   "metadata": {},
   "source": [
    "# Text Vectorization and Similarity Analysis\n",
    "\n",
    "This notebook shows how to convert text into numbers and measure similarity between documents.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a11d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/sudarshan/Desktop/Workshop/git_repo/.venv/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: scikit-learn in /home/sudarshan/Desktop/Workshop/git_repo/.venv/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/sudarshan/Desktop/Workshop/git_repo/.venv/lib/python3.12/site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sudarshan/Desktop/Workshop/git_repo/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sudarshan/Desktop/Workshop/git_repo/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/sudarshan/Desktop/Workshop/git_repo/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/sudarshan/Desktop/Workshop/git_repo/.venv/lib/python3.12/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/sudarshan/Desktop/Workshop/git_repo/.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/sudarshan/Desktop/Workshop/git_repo/.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/sudarshan/Desktop/Workshop/git_repo/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f648542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sudarshan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sudarshan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/sudarshan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Download required data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Setup preprocessing tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Complete text preprocessing pipeline\"\"\"\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0073d3a3",
   "metadata": {},
   "source": [
    "## Sample Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5618dfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents after cleaning:\n",
      "love machine learning machine learning cool\n",
      "machine learning amazing\n",
      "hate bad weather\n",
      "weather great today\n",
      "python programming relly fun\n",
      "enjoy learning data science python dont\n"
     ]
    }
   ],
   "source": [
    "raw_documents = [\n",
    "    \"I love machine learning. Machine learning is cool\",\n",
    "    \"Machine learning is amazing\", \n",
    "    \"I hate bad weather\",\n",
    "    \"The weather is great today\",\n",
    "    \"Python programming is relly fun\",\n",
    "    \"I enjoy learning data science with Python, don't you?\"\n",
    "]\n",
    "\n",
    "# Clean the documents\n",
    "documents = [clean_text(doc) for doc in raw_documents]\n",
    "\n",
    "print(\"Documents after cleaning:\")\n",
    "\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25552132",
   "metadata": {},
   "source": [
    "## 1. Bag of Words (BoW)\n",
    "\n",
    "**What is it?** Count how many times each word appears in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14974c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['amazing', 'bad', 'cool', 'data', 'dont', 'enjoy', 'fun', 'great', 'hate', 'learning', 'love', 'machine', 'programming', 'python', 'relly', 'science', 'today', 'weather']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>bad</th>\n",
       "      <th>cool</th>\n",
       "      <th>data</th>\n",
       "      <th>dont</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>fun</th>\n",
       "      <th>great</th>\n",
       "      <th>hate</th>\n",
       "      <th>learning</th>\n",
       "      <th>love</th>\n",
       "      <th>machine</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "      <th>relly</th>\n",
       "      <th>science</th>\n",
       "      <th>today</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazing  bad  cool  data  dont  enjoy  fun  great  hate  learning  love  \\\n",
       "0        0    0     1     0     0      0    0      0     0         2     1   \n",
       "1        1    0     0     0     0      0    0      0     0         1     0   \n",
       "2        0    1     0     0     0      0    0      0     1         0     0   \n",
       "3        0    0     0     0     0      0    0      1     0         0     0   \n",
       "4        0    0     0     0     0      0    1      0     0         0     0   \n",
       "5        0    0     0     1     1      1    0      0     0         1     0   \n",
       "\n",
       "   machine  programming  python  relly  science  today  weather  \n",
       "0        2            0       0      0        0      0        0  \n",
       "1        1            0       0      0        0      0        0  \n",
       "2        0            0       0      0        0      0        1  \n",
       "3        0            0       0      0        0      1        1  \n",
       "4        0            1       1      1        0      0        0  \n",
       "5        0            0       1      0        1      0        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Create BoW vectors\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow_matrix = bow_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Show the vocabulary\n",
    "vocab = bow_vectorizer.get_feature_names_out()\n",
    "print(f\"Vocabulary: {list(vocab)}\")\n",
    "\n",
    "# Convert to DataFrame to see it clearly\n",
    "bow_df = pd.DataFrame(\n",
    "    bow_matrix.toarray(), \n",
    "    columns=vocab,\n",
    ")\n",
    "\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c0777",
   "metadata": {},
   "source": [
    "## 2. TF-IDF\n",
    "\n",
    "**What is it?** Give higher weight to words that are:\n",
    "- Common in one document \n",
    "- Rare across all documents\n",
    "\n",
    "**Why?** Words that appear often in one document but rarely in others are more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8502053b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>bad</th>\n",
       "      <th>cool</th>\n",
       "      <th>data</th>\n",
       "      <th>dont</th>\n",
       "      <th>enjoy</th>\n",
       "      <th>fun</th>\n",
       "      <th>great</th>\n",
       "      <th>hate</th>\n",
       "      <th>learning</th>\n",
       "      <th>love</th>\n",
       "      <th>machine</th>\n",
       "      <th>programming</th>\n",
       "      <th>python</th>\n",
       "      <th>relly</th>\n",
       "      <th>science</th>\n",
       "      <th>today</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.389047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538684</td>\n",
       "      <td>0.389047</td>\n",
       "      <td>0.638048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.681722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.471964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.559022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611713</td>\n",
       "      <td>0.501613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.521823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.521823</td>\n",
       "      <td>0.427903</td>\n",
       "      <td>0.521823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440579</td>\n",
       "      <td>0.440579</td>\n",
       "      <td>0.440579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.440579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amazing       bad      cool      data      dont     enjoy       fun  \\\n",
       "0  0.000000  0.000000  0.389047  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.681722  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.611713  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.521823   \n",
       "5  0.000000  0.000000  0.000000  0.440579  0.440579  0.440579  0.000000   \n",
       "\n",
       "      great      hate  learning      love   machine  programming    python  \\\n",
       "0  0.000000  0.000000  0.538684  0.389047  0.638048     0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.471964  0.000000  0.559022     0.000000  0.000000   \n",
       "2  0.000000  0.611713  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "3  0.611713  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000     0.521823  0.427903   \n",
       "5  0.000000  0.000000  0.305018  0.000000  0.000000     0.000000  0.361281   \n",
       "\n",
       "      relly   science     today   weather  \n",
       "0  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.501613  \n",
       "3  0.000000  0.000000  0.611713  0.501613  \n",
       "4  0.521823  0.000000  0.000000  0.000000  \n",
       "5  0.000000  0.440579  0.000000  0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(), \n",
    "    columns=tfidf_vectorizer.get_feature_names_out(),\n",
    ")\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dda688c",
   "metadata": {},
   "source": [
    "## 3. Cosine Similarity\n",
    "\n",
    "**What is it?** Measures how similar two documents are by looking at the angle between their vectors.\n",
    "\n",
    "**Why use it?** It ignores document length and focuses on which words are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0903b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.610922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.251616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.164308</td>\n",
       "      <td>0.143958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154593</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0  1.000000  0.610922  0.000000  0.000000  0.000000  0.164308\n",
       "1  0.610922  1.000000  0.000000  0.000000  0.000000  0.143958\n",
       "2  0.000000  0.000000  1.000000  0.251616  0.000000  0.000000\n",
       "3  0.000000  0.000000  0.251616  1.000000  0.000000  0.000000\n",
       "4  0.000000  0.000000  0.000000  0.000000  1.000000  0.154593\n",
       "5  0.164308  0.143958  0.000000  0.000000  0.154593  1.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Make it into a nice table\n",
    "similarity_df = pd.DataFrame(\n",
    "    similarity_matrix,\n",
    ")\n",
    "\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d621378",
   "metadata": {},
   "source": [
    "# 4. KNN (K-Nearest neighbours)\n",
    "\n",
    "K-Nearest Neighbors (KNN) is one of the simplest machine learning algorithms.\n",
    "\n",
    "Unlike models that \"learn\" patterns during training, KNN is called a lazy learner:\n",
    "- It does not train a model.\n",
    "- It stores all training data.\n",
    "- When asked to make a prediction, it compares the new input to the stored data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c19cce66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 nearest neighbors:\n",
      "1. Point: [6 5], Distance: 1.00\n",
      "2. Point: [7 7], Distance: 2.83\n",
      "3. Point: [8 6], Distance: 3.16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "points = np.array([\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [3, 1],\n",
    "    [6, 5],\n",
    "    [7, 7],\n",
    "    [8, 6]\n",
    "])\n",
    "\n",
    "# The new point\n",
    "query_point = np.array([[5, 5]])\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=3, metric='euclidean')\n",
    "nn.fit(points)\n",
    "\n",
    "distances, indices = nn.kneighbors(query_point)\n",
    "\n",
    "# Print results\n",
    "print(\"3 nearest neighbors:\")\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    print(f\"{i+1}. Point: {points[idx]}, Distance: {distances[0][i]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
